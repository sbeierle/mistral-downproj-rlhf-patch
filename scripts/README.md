# ğŸ§  Core Scripts â€“ Patch Discovery & Token Analysis

This folder contains the **core logic scripts** used in Hydra | Mistral vDERAW | Phase 2.  
All scripts have been partially obfuscated or rewritten to protect sensitive model interactions.

---

## âš™ï¸ Script Categories

### ğŸ”¬ Token Attention & Routing

- `prompt_pathfinder.py`  
  Compares attention routes between a *trigger prompt* and a *neutral prompt*  
  â†’ Outputs heatmaps highlighting suspicious token flow

- `attention_heatmap_logger.py`  
  Logs and visualizes attention across all layers for a given prompt  
  â†’ Use for single-run attention diagnostics

---

### ğŸ§® Neuron Scanning & Patch Prep

- `boost_explorer_from_csv.py`  
  Loads activation logs and identifies patch-worthy neurons by threshold  
  â†’ Used for `down_proj.weight` patch targeting

- `scan_mlp_neuron_norms.py`  
  Scans all `mlp.down_proj` tensors for abnormally high norms  
  â†’ Generates CSV for manual or automated patching

- `neuron_patch_from_csv.py`  
  Applies targeted modifications to selected neurons  
  â†’ Controlled norm-level patching based on CSV

---

## ğŸ” Safety Notice

This repository does **not** expose full patch logic, vector injection methods, or structural weights.  
The showcased scripts have been modified to illustrate workflow â€” without leaking critical details.

---

## ğŸ“ Suggested Workflow

1. **Run `prompt_pathfinder.py`** to identify token routing anomalies  
2. **Scan with `scan_mlp_neuron_norms.py`** to find suspect neurons  
3. **Use `boost_explorer_from_csv.py`** to prep a target neuron list  
4. **Apply patches** via `neuron_patch_from_csv.py` (optional / demo)

---

## ğŸ§ª Notes

- All prompts used in this repo are **sanitized academic examples**  
- Sensitive injection logic has been redacted or replaced with placeholders  
- Full downstream patch systems are retained privately for security reasons

---

ğŸ“ For visual diagnostics, check the [`visual_tools/`](../visual_tools) folder.
